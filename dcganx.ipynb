{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam\n",
    "from tqdm import tqdm\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Nadam, Adam, SGD\n",
    "from keras.metrics import categorical_accuracy, binary_accuracy\n",
    "from keras.regularizers import l2\n",
    "from scipy.misc import imresize\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import glob\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To read the images in numerical order\n",
    "import re\n",
    "numbers = re.compile(r'(\\d+)')\n",
    "def numericalSort(value):\n",
    "    parts = numbers.split(value)\n",
    "    parts[1::2] = map(int, parts[1::2])\n",
    "    return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing all the images into 4d arrays.\n",
    "\n",
    "'''The images in the dataset are arranged into mupltiple folders of multiple subfolders and we need to read all\n",
    "the images in all the subfolders into a single array. So, first we willl be reading all the files names including\n",
    "their paths which are stored as a list named filelist. After that using these paths we read the images as arrays\n",
    "and make a 4D array'''\n",
    "\n",
    "a = sorted(glob.glob('/home/manideep/Downloads/lsun_bedroom/sample/data0/lsun/bedroom/*'), key=numericalSort)\n",
    "\n",
    "b = []\n",
    "for i in a:\n",
    "    b.extend(sorted(glob.glob(i+'/*'), key=numericalSort))\n",
    "\n",
    "c = []\n",
    "for i in b:\n",
    "    c.extend(sorted(glob.glob(i+'/*'), key=numericalSort))\n",
    "\n",
    "filelist = []\n",
    "for i in c:\n",
    "    filelist.extend(sorted(glob.glob(i+'/*.jpg'), key=numericalSort))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the images and making a 4d array for training\n",
    "\n",
    "X_train = np.array([imresize(np.asarray(Image.open(fname)), (64,64)) for fname in filelist[:1000]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image shape information\n",
    "img_shape = X_train.shape[1:]\n",
    "latent_dim = 100\n",
    "\n",
    "optimizer = Adam(lr=0.0002, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generator\n",
    "\n",
    "def generator():\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(1024*4*4, input_dim = latent_dim, activation = 'relu'))\n",
    "    model.add(Reshape((4,4,1024)))\n",
    "    model.add(BatchNormalization(momentum=0.5))\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(512, kernel_size=3, padding=\"same\", activation = 'relu'))\n",
    "    model.add(BatchNormalization(momentum=0.5))\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(256, kernel_size=3, padding=\"same\", activation = 'relu'))\n",
    "    model.add(BatchNormalization(momentum=0.5))\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128, kernel_size=3, padding=\"same\", activation = 'relu'))\n",
    "    model.add(BatchNormalization(momentum=0.5))\n",
    "    model.add(UpSampling2D())\n",
    "    # For output layer, use tanh activation and BatchNormalization shouldn't be used as told in the paper\n",
    "    model.add(Conv2D(3, kernel_size=3, padding=\"same\", activation = 'tanh'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    noise = Input(shape=(latent_dim,))\n",
    "    img = model(noise)\n",
    "\n",
    "    return Model(noise, img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Discriminator\n",
    "\n",
    "def discriminator():\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=1, input_shape=img_shape, padding='valid'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(256, kernel_size=3, strides=1, padding='valid'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.5))\n",
    "    model.add(Conv2D(512, kernel_size=3, strides=1, padding='valid'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.5))\n",
    "    model.add(Conv2D(1024, kernel_size=3, strides=1, padding='valid'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    img = Input(shape=img_shape)\n",
    "    validity = model(img)\n",
    "\n",
    "    return Model(img, validity)\n",
    "\n",
    "discriminator = discriminator()\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build the generator\n",
    "generator = generator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The generator takes noise as input and generates imgs\n",
    "z = Input(shape=(latent_dim,))\n",
    "img = generator(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# For the combined model we will only train the generator\n",
    "discriminator.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The discriminator takes generated images as input and determines validity\n",
    "valid = discriminator(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The combined model  (stacked generator and discriminator)\n",
    "# Trains the generator to fool the discriminator\n",
    "combined = Model(z, valid)\n",
    "combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "def save_imgs(epoch):\n",
    "    r, c = 5, 5\n",
    "    noise = np.random.normal(0, 1, (r * c, latent_dim))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "\n",
    "    # Rescale images 0 - 1\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "            axs[i,j].axis('off')\n",
    "            cnt += 1\n",
    "    fig.savefig(\"images/epoch_%d.png\" % epoch)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training both generator and discriminator\n",
    "\n",
    "epochs = 100\n",
    "batch_size=128\n",
    "save_interval=5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Rescale -1 to 1\n",
    "X_train = X_train / 127.5 - 1.\n",
    "#X_train = np.expand_dims(X_train, axis=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Adversarial ground truths\n",
    "valid = np.ones((batch_size, 1))\n",
    "fake = np.zeros((batch_size, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring empty lists to save the losses for plotting\n",
    "d_loss_plot = []\n",
    "g_loss_plot = []\n",
    "acc_plot = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "        \n",
    "    start = time.time()\n",
    "\n",
    "    #  Training the Discriminator\n",
    "\n",
    "    # Select a random half of images\n",
    "    idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "    imgs = X_train[idx]\n",
    "\n",
    "    # Sample noise and generate a batch of new images\n",
    "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "\n",
    "    # Train the discriminator (real classified as ones and generated as zeros)\n",
    "    d_loss_real = discriminator.train_on_batch(imgs, valid)\n",
    "    d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "    #  Training the Generator\n",
    "\n",
    "    # Train the generator (wants discriminator to mistake images as real)\n",
    "    g_loss = combined.train_on_batch(noise, valid)\n",
    "        \n",
    "    end = time.time()\n",
    "    epoch_time = end - start\n",
    "    \n",
    "    # Saving the Discriminator and Generator losses and accuracy for plotting\n",
    "    d_loss_plot.append(d_loss[0])\n",
    "    g_loss_plot.append(g_loss)\n",
    "    acc_plot.append(d_loss[1])\n",
    "\n",
    "    # Plot the progress\n",
    "    print(\"Epoch %d/%d - %d s - D loss: %f - acc.: %.2f%% - G loss: %f\" % \n",
    "          (epoch, epochs, epoch_time, d_loss[0], 100 * d_loss[1], g_loss))\n",
    "\n",
    "    # If at save interval => save generated image samples\n",
    "    if epoch % save_interval == 0:\n",
    "        save_imgs(epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ploting losses and accuracy\n",
    "\n",
    "# Discriminator accuracy plot \n",
    "plt.plot(acc_plot)\n",
    "plt.title('Discriminator accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "\n",
    "# Loss plots\n",
    "plt.plot(d_loss_plot)\n",
    "plt.plot(g_loss_plot)\n",
    "plt.title('Losses')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Discriminator', 'Generator'])\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
